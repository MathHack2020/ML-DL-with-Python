{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('../data/Clean_Dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../imgs/featureEngin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.airline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source_city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.destination_city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.departure_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.arrival_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stops.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the  of  duration of the flights\n",
    "\n",
    "df.duration.describe().T[[\"min\", \"max\", \"mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepross dataframe \n",
    "df.drop([\"flight\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encoding \n",
    "df[\"class\"]= df[\"class\"].apply(lambda x: 1 if x==\"Economy\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode \"stops\" features \n",
    "df[\"stops\"].unique()\n",
    "# df[\"stops\"]= df[\"stops\"].apply(lambda x: 0 if x==\"non-stop\" else 1\n",
    "pd.factorize(df[\"stops\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stops = pd.factorize(df[\"stops\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onrhot encpding  of airine  feature of  our datsset \n",
    "pd.get_dummies(df, columns=[\"airline\"], drop_first=True, prefix=\"AirL\", dtype=int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df.select_dtypes(include=\"object\").columns\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encode all object type features\n",
    "# diaplay all features columns  ( max columns)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.get_dummies(df, columns=cat_features, drop_first=True, prefix=cat_features, dtype=int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can proceed more  by onehot encoding all categorical features of our dataset\n",
    "\n",
    "df= pd.get_dummies(df, drop_first=True ,  dtype=int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../imgs/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../imgs/dataSplit.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(\"price\", axis=1)\n",
    "y= df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a randomforest regressor from sklearn \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg= RandomForestRegressor(n_estimators=50, random_state=46, n_jobs=-1)\n",
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../imgs/metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print main  metrics  score of the model\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import R2 , mean_squared_error  and mean absolute error from sklearn.metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "y_pred=reg.predict(X_test)\n",
    "print(f\"    R2   {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"    Mean Squared Error MSE :  {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"    MAE  :  {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "print(f\"    RMSE  :  {math.sqrt(mean_squared_error(y_test, y_pred)):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot  y_test vs y_pred\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, y_pred, c=\"lightcoral\")\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.title(\"y_test vs y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.describe().T# describe the price of the flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display most important 5 features of the model\n",
    "\n",
    "import numpy as np\n",
    "importances = reg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X.columns[i] for i in indices]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Top 5 Feature Importance\")\n",
    "plt.bar(range(5), importances[indices[:5]])\n",
    "plt.xticks(range(5), names[:5], rotation=45, ha=\"right\") # Rotate labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proceed through gridseachcv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200], # The number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt'], # The number of features to consider when looking for the best split\n",
    "    'max_depth': [None, 10, 20, 30,], # The maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10], # The minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4] # The minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=reg, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best param\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizeGridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import randomizeserachcv \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200], # The number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt'], # The number of features to consider when looking for the best split\n",
    "    'max_depth': [None, 10, 20, 30,], # The maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10], # The minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4] # The minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=reg, param_distributions=param_grid, n_iter=100, cv=5, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
